"""
æ‰‹éƒ¨è·Ÿéšæ¨¡å¼
å€Ÿé‰´ hand_pose_demo_zeroMQ.py çš„ç®—æ³•
è·å–æ‰‹éƒ¨ position, euler, openness
"""
import cv2
import math
import numpy as np
from typing import Optional, Tuple, Dict, Any
from .base_mode import BaseMode
from ..utils.kinematics import (
    inverse_kinematics,
    angle_to_encoder,
    pose_to_encoders,
    get_home_encoders,
    SERVO_CONFIG,
    SERVO_LIMITS,
    ARM_LENGTH,
)


# ========== æ‰‹éƒ¨æ£€æµ‹å™¨ï¼ˆå†…åµŒç‰ˆæœ¬ï¼‰==========
OPERATOR2MANO_RIGHT = np.array([[0, 0, -1], [-1, 0, 0], [0, 1, 0]])
OPERATOR2MANO_LEFT = np.array([[0, 0, -1], [1, 0, 0], [0, -1, 0]])


def compute_hand_openness(joint_pos, eps=1e-6):
    """è®¡ç®—æ‰‹æŒå¼ å¼€ç¨‹åº¦"""
    if joint_pos is None:
        return None, None
    palm_center = np.mean(joint_pos[[0, 5, 9, 13, 17]], axis=0)
    fingertips = joint_pos[[4, 8, 12, 16, 20]]
    distances = np.linalg.norm(fingertips - palm_center, axis=1)
    palm_width = np.linalg.norm(joint_pos[5] - joint_pos[17])
    denom = palm_width if palm_width >= eps else max(np.max(distances), eps)
    openness = float(np.clip(np.mean(distances) / denom, 0.0, 3.0))
    return openness, distances


def detect_pointing_one(joint_pos, eps=1e-6):
    """
    æ£€æµ‹"æ¯”1"æ‰‹åŠ¿ï¼ˆé£ŸæŒ‡ä¼¸ç›´ï¼Œå…¶ä»–æ‰‹æŒ‡å¼¯æ›²ï¼‰
    
    MediaPipe å…³é”®ç‚¹:
    - 4: æ‹‡æŒ‡å°–, 8: é£ŸæŒ‡å°–, 12: ä¸­æŒ‡å°–, 16: æ— åæŒ‡å°–, 20: å°æŒ‡å°–
    - 0: æ‰‹è…•, 5: é£ŸæŒ‡æ ¹, 9: ä¸­æŒ‡æ ¹, 13: æ— åæŒ‡æ ¹, 17: å°æŒ‡æ ¹
    
    Returns:
        bool: æ˜¯å¦ä¸º"æ¯”1"æ‰‹åŠ¿
    """
    if joint_pos is None:
        return False
    
    # è®¡ç®—æ‰‹æŒå®½åº¦ä½œä¸ºå‚è€ƒ
    palm_width = np.linalg.norm(joint_pos[5] - joint_pos[17])
    if palm_width < eps:
        return False
    
    # è®¡ç®—å„æ‰‹æŒ‡æŒ‡å°–åˆ°æ‰‹è…•çš„è·ç¦»ï¼ˆå½’ä¸€åŒ–ï¼‰
    wrist = joint_pos[0]
    
    # é£ŸæŒ‡ä¼¸ç›´ï¼šæŒ‡å°–åˆ°æ‰‹è…•è·ç¦» > æŒ‡æ ¹åˆ°æ‰‹è…•è·ç¦» * 1.3
    index_tip_dist = np.linalg.norm(joint_pos[8] - wrist)
    index_mcp_dist = np.linalg.norm(joint_pos[5] - wrist)
    index_extended = index_tip_dist > index_mcp_dist * 1.3
    
    # å…¶ä»–æ‰‹æŒ‡å¼¯æ›²ï¼šæŒ‡å°–åˆ°æ‰‹è…•è·ç¦» < æŒ‡æ ¹åˆ°æ‰‹è…•è·ç¦» * 1.2
    # ä¸­æŒ‡
    middle_tip_dist = np.linalg.norm(joint_pos[12] - wrist)
    middle_mcp_dist = np.linalg.norm(joint_pos[9] - wrist)
    middle_bent = middle_tip_dist < middle_mcp_dist * 1.2
    
    # æ— åæŒ‡
    ring_tip_dist = np.linalg.norm(joint_pos[16] - wrist)
    ring_mcp_dist = np.linalg.norm(joint_pos[13] - wrist)
    ring_bent = ring_tip_dist < ring_mcp_dist * 1.2
    
    # å°æŒ‡
    pinky_tip_dist = np.linalg.norm(joint_pos[20] - wrist)
    pinky_mcp_dist = np.linalg.norm(joint_pos[17] - wrist)
    pinky_bent = pinky_tip_dist < pinky_mcp_dist * 1.2
    
    # æ‹‡æŒ‡ï¼ˆå¯ä»¥ä¼¸ç›´æˆ–å¼¯æ›²ï¼Œä¸å¼ºåˆ¶è¦æ±‚ï¼‰
    
    return index_extended and middle_bent and ring_bent and pinky_bent


class EmbeddedSingleHandDetector:
    """å†…åµŒçš„å•æ‰‹æ£€æµ‹å™¨ï¼ˆåŸºäº MediaPipeï¼‰"""
    
    def __init__(self, hand_type="Right", min_detection_confidence=0.8,
                 min_tracking_confidence=0.8, selfie=False,
                 use_pose=False, real_palm_width=0.085):
        import mediapipe as mp
        
        self.mp = mp
        self.hand_detector = mp.solutions.hands.Hands(
            static_image_mode=False,
            max_num_hands=1,
            min_detection_confidence=min_detection_confidence,
            min_tracking_confidence=min_tracking_confidence,
        )
        self.use_pose = use_pose
        self.real_palm_width = real_palm_width
        self.selfie = selfie
        self.operator2mano = OPERATOR2MANO_RIGHT if hand_type == "Right" else OPERATOR2MANO_LEFT
        inverse_hand_dict = {"Right": "Left", "Left": "Right"}
        self.detected_hand_type = hand_type if selfie else inverse_hand_dict[hand_type]

    @staticmethod
    def parse_keypoint_3d(keypoint_3d) -> np.ndarray:
        keypoint = np.empty([21, 3], dtype=np.float32)
        for i in range(21):
            keypoint[i, 0] = keypoint_3d.landmark[i].x
            keypoint[i, 1] = keypoint_3d.landmark[i].y
            keypoint[i, 2] = keypoint_3d.landmark[i].z
        return keypoint

    @staticmethod
    def estimate_frame_from_hand_points(keypoint_3d_array: np.ndarray) -> np.ndarray:
        assert keypoint_3d_array.shape == (21, 3)
        points = keypoint_3d_array[[0, 5, 9], :]
        x_vector = points[0] - points[2]
        pts_centered = points - np.mean(points, axis=0, keepdims=True)
        u, s, v = np.linalg.svd(pts_centered)
        normal = v[2, :]
        x = x_vector - np.sum(x_vector * normal) * normal
        x /= (np.linalg.norm(x) + 1e-8)
        z = np.cross(x, normal)
        if np.sum(z * (points[1] - points[2])) < 0:
            normal *= -1
            z *= -1
        frame = np.stack([x, normal, z], axis=1)
        return frame

    def detect(self, rgb):
        results = self.hand_detector.process(rgb)
        if not results or not results.multi_hand_landmarks:
            return 0, None, None, None, None, None, None

        # æ‰¾åˆ°ç›®æ ‡æ‰‹
        desired_hand_num = -1
        for i, hand_handedness in enumerate(results.multi_handedness):
            label = hand_handedness.classification[0].label
            if label == self.detected_hand_type:
                desired_hand_num = i
                break
        if desired_hand_num < 0:
            return 0, None, None, None, None, None, None

        keypoint_3d = results.multi_hand_world_landmarks[desired_hand_num]
        keypoint_2d = results.multi_hand_landmarks[desired_hand_num]
        num_box = len(results.multi_hand_landmarks)

        # è½¬ä¸ºnumpy
        keypoint_3d_raw = self.parse_keypoint_3d(keypoint_3d)
        wrist_world_pos = keypoint_3d_raw[0].copy()

        # wrist-centered
        keypoint_3d_centered = keypoint_3d_raw - wrist_world_pos[None, :]

        # æ—‹è½¬çŸ©é˜µ
        wrist_rot = self.estimate_frame_from_hand_points(keypoint_3d_centered)
        joint_pos = keypoint_3d_centered @ wrist_rot @ self.operator2mano

        # openness
        openness, distances = compute_hand_openness(joint_pos)

        # ä½¿ç”¨æ‰‹æŒå®½åº¦æ¯”ä¾‹ç¼©æ”¾å¾—åˆ°è¿‘ä¼¼çœŸå®ä¸–ç•Œåæ ‡
        joint_pos_world = joint_pos.copy()
        if self.real_palm_width > 0:
            palm_width_pixel = np.linalg.norm(joint_pos[[5, 17], :], axis=1).sum()
            scale = self.real_palm_width / max(palm_width_pixel, 1e-6)
            joint_pos_world *= scale

        return int(num_box), joint_pos, keypoint_2d, wrist_rot, openness, wrist_world_pos, joint_pos_world

    def close(self):
        if self.hand_detector:
            self.hand_detector.close()


# æ³¨: é€†è§£ç®—å¸¸é‡å’Œé…ç½®å·²ç§»åˆ° utils/kinematics.py


class HandFollowMode(BaseMode):
    """
    æ‰‹éƒ¨è·Ÿéšæ¨¡å¼
    
    è¯»å–æ•°æ®ï¼š
    - position: æ‰‹éƒ¨3Dä½ç½® [x, y, z]
    - euler: æ‰‹éƒ¨æ¬§æ‹‰è§’ [roll, pitch, yaw]
    - openness: æ‰‹æŒå¼ å¼€ç¨‹åº¦ (0-1)
    
    èˆµæœºé…ç½®ï¼ˆ3ä¸ªèˆµæœºï¼‰ï¼š
    - èˆµæœº1ï¼šåº•åº§æ—‹è½¬ï¼ˆyawï¼‰
    - èˆµæœº2ï¼šç¬¬ä¸€å…³èŠ‚ä¿¯ä»°ï¼ˆpitchï¼‰
    - èˆµæœº3ï¼šç¬¬äºŒå…³èŠ‚ä¿¯ä»°ï¼ˆrollï¼‰
    """
    
    MODE_NAME = "æ‰‹éƒ¨è·Ÿéš"
    
    def __init__(self, controller):
        super().__init__(controller)
        
        # èˆµæœºé…ç½®ï¼ˆä½¿ç”¨å…±äº«çš„é€†è§£ç®—é…ç½®ï¼‰
        self.servo_ids = [1, 2, 3]
        self.servo_limits = SERVO_LIMITS  # ä½¿ç”¨å…±äº«é…ç½®
        self.current_positions = {1: 475, 2: 500, 3: 400}
        
        # æ‰‹éƒ¨æ£€æµ‹ç›¸å…³
        self._hand_detector = None
        self._kalman_filter = None
        self._camera_matrix = None
        self._use_single_hand_detector = False
        
        # ç”¨äº PnP æ±‚è§£çš„å…³é”®ç‚¹ç´¢å¼•
        # 0: WRIST, 5: INDEX_MCP, 9: MIDDLE_MCP, 13: RING_MCP, 17: PINKY_MCP
        self._keypoint_indices = [0, 5, 9, 13, 17]
        
        # æœ€æ–°çš„æ‰‹éƒ¨æ•°æ®
        self._hand_data: Optional[Dict[str, Any]] = None
        self._no_hand_count = 0
        self._no_hand_threshold = 30
        
        # è·ç¦»å†å²ï¼ˆç”¨äºå¼‚å¸¸æ£€æµ‹ï¼‰
        self._distance_history = []
        self._max_history = 30
        
        # èˆµæœºå‘é€é¢‘ç‡æ§åˆ¶
        self._servo_send_interval = 0.1  # 10Hzï¼Œå¯è°ƒæ•´
        self._last_servo_send_time = 0
        
        # æ¡æ‹³æš‚åœåŠŸèƒ½
        self._paused = False  # æ˜¯å¦å¤„äºæš‚åœçŠ¶æ€
        self._pause_threshold = 0.7   # openness < æ­¤å€¼æ—¶æš‚åœ
        self._resume_threshold = 0.9  # openness > æ­¤å€¼æ—¶æ¢å¤
        
        # æ¯”1æ‰‹åŠ¿é€€å‡ºåŠŸèƒ½
        self._pointing_one_start_time = None  # æ¯”1æ‰‹åŠ¿å¼€å§‹æ—¶é—´
        self._pointing_one_exit_seconds = 3.0  # æ¯”1æ‰‹åŠ¿æŒç»­å¤šå°‘ç§’åé€€å‡º
        
    def on_enter(self):
        """è¿›å…¥æ¨¡å¼ï¼šåˆå§‹åŒ–æ£€æµ‹å™¨"""
        self._print("[DEBUG] on_enter() å¼€å§‹")
        self._print(f"[DEBUG] controller = {self.controller}")
        if self.controller:
            servo_thread = getattr(self.controller, '_servo_thread', None)
            self._print(f"[DEBUG] _servo_thread = {servo_thread}")
            if servo_thread:
                self._print(f"[DEBUG] servo_thread.is_alive() = {servo_thread.is_alive()}")
        self._init_hand_detector()
        self._init_kalman_filter()
        self._move_to_home()
        self._print("ç­‰å¾…æ£€æµ‹æ‰‹éƒ¨...")
        self._print("è¯»å–æ•°æ®: position, euler, openness")
        
    def on_exit(self):
        """é€€å‡ºæ¨¡å¼ï¼šé‡Šæ”¾èµ„æº"""
        if self._hand_detector:
            self._hand_detector.close()
            self._hand_detector = None
        self._move_to_home()
        
    def _init_hand_detector(self):
        """åˆå§‹åŒ–æ‰‹éƒ¨æ£€æµ‹å™¨"""
        try:
            # ä½¿ç”¨å†…åµŒçš„ SingleHandDetector
            self._hand_detector = EmbeddedSingleHandDetector(
                hand_type="Right",
                min_detection_confidence=0.8,
                min_tracking_confidence=0.8,
                use_pose=False,
                real_palm_width=0.085
            )
            self._use_single_hand_detector = True
            self._print("ä½¿ç”¨ EmbeddedSingleHandDetector")
            
        except ImportError as e:
            self._print(f"æ‰‹éƒ¨æ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self._hand_detector = None
            
    def _init_kalman_filter(self):
        """åˆå§‹åŒ–å¡å°”æ›¼æ»¤æ³¢å™¨ï¼ˆç®€åŒ–ç‰ˆï¼Œä¸ä¾èµ–å¤–éƒ¨æ¨¡å—ï¼‰"""
        # ä½¿ç”¨ç®€å•çš„æŒ‡æ•°å¹³æ»‘ä»£æ›¿å¡å°”æ›¼æ»¤æ³¢
        self._kalman_filter = None
        self._smooth_alpha = 0.3  # å¹³æ»‘ç³»æ•°
        self._smooth_state = None
        self._print("ä½¿ç”¨ç®€å•å¹³æ»‘æ»¤æ³¢")
            
    def _calibrate_camera(self, frame_shape):
        """ç®€å•çš„ç›¸æœºæ ‡å®š"""
        if self._camera_matrix is None:
            h, w = frame_shape[:2]
            fx = fy = w * 1.2
            cx, cy = w / 2, h / 2
            self._camera_matrix = np.array([
                [fx, 0, cx],
                [0, fy, cy],
                [0, 0, 1]
            ], dtype=np.float32)
            self._dist_coeffs = np.zeros(5)
            
    def _move_to_home(self):
        """ç§»åŠ¨åˆ°åˆå§‹ä½ç½®ï¼ˆç›´ç«‹ä¸­ä½ï¼‰"""
        # ç›´ç«‹ä¸­ä½: b=0.1, theta_0=90, beta=0
        home_positions = {3: 598, 2: 77, 1: 276}
        self._move_servos(home_positions, speed=250)
        self.current_positions = home_positions.copy()
        
    def update(self, frame=None, voice_text: str = None) -> bool:
        """æ›´æ–°æ¨¡å¼"""
        if frame is None:
            return True
            
        # ç›¸æœºæ ‡å®š
        self._calibrate_camera(frame.shape)
        
        # æ£€æµ‹æ‰‹éƒ¨ï¼Œè·å– position, euler, openness
        hand_data = self._detect_hand(frame)
        
        if hand_data:
            self._no_hand_count = 0
            self._hand_data = hand_data
            
            # æ‰“å°æ‰‹éƒ¨æ•°æ®
            pos = hand_data['position']
            euler = hand_data['euler']
            openness = hand_data['openness']
            ik_input = hand_data['ik_input']
            
            # åŸå§‹æ•°æ®
            self._debug(f"Pos: [{pos[0]:.3f}, {pos[1]:.3f}, {pos[2]:.3f}] | "
                       f"Euler: [{euler[0]:.1f}, {euler[1]:.1f}, {euler[2]:.1f}] | "
                       f"Open: {openness:.2f}")
            
            # === è·å–å…³èŠ‚ä½ç½®ç”¨äºæ‰‹åŠ¿æ£€æµ‹ ===
            joint_pos = hand_data.get('joint_pos')
            
            # === æ¯”1æ‰‹åŠ¿æ£€æµ‹ï¼ˆé€€å‡ºåŠŸèƒ½ï¼‰ ===
            import time
            is_pointing_one = detect_pointing_one(joint_pos) if joint_pos is not None else False
            
            if is_pointing_one:
                if self._pointing_one_start_time is None:
                    # å¼€å§‹è®¡æ—¶
                    self._pointing_one_start_time = time.time()
                    self._paused = True  # æ¯”1ä¹Ÿä¼šæš‚åœ
                    self._print("â˜ï¸ æ£€æµ‹åˆ°æ¯”1æ‰‹åŠ¿ï¼Œæš‚åœä¸­...")
                else:
                    # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é€€å‡ºæ—¶é—´
                    elapsed = time.time() - self._pointing_one_start_time
                    remaining = self._pointing_one_exit_seconds - elapsed
                    if remaining > 0:
                        self._debug(f"[æ¯”1æ‰‹åŠ¿] ä¿æŒ {elapsed:.1f}sï¼Œè¿˜éœ€ {remaining:.1f}s é€€å‡º")
                    else:
                        self._print(f"â˜ï¸ æ¯”1æ‰‹åŠ¿ä¿æŒ {self._pointing_one_exit_seconds}sï¼Œé€€å‡ºæ¨¡å¼")
                        return False  # è¿”å› False é€€å‡ºæ¨¡å¼
            else:
                # ä¸æ˜¯æ¯”1æ‰‹åŠ¿ï¼Œé‡ç½®è®¡æ—¶
                if self._pointing_one_start_time is not None:
                    self._pointing_one_start_time = None
                    self._print("â˜ï¸ æ¯”1æ‰‹åŠ¿å–æ¶ˆ")
                
                # === æ¡æ‹³æš‚åœåŠŸèƒ½ ===
                if not self._paused and openness < self._pause_threshold:
                    # è¿›å…¥æš‚åœçŠ¶æ€
                    self._paused = True
                    self._print(f"âœ‹ æ¡æ‹³æš‚åœ (openness={openness:.2f})")
                elif self._paused and openness > self._resume_threshold:
                    # æ¢å¤è·Ÿéš
                    self._paused = False
                    self._print(f"ğŸ‘‹ æ¢å¤è·Ÿéš (openness={openness:.2f})")
            
            # æš‚åœæ—¶ä¸ç§»åŠ¨èˆµæœº
            if self._paused:
                self._debug(f"[æš‚åœä¸­] openness={openness:.2f}, éœ€è¦>{self._resume_threshold:.1f}æ¢å¤")
                return True
            
            # é€†è§£è¾“å…¥æ•°ç»„: [pitch, middle_mcp_y, distance]
            self._debug(f"IK Input: [pitch={ik_input[0]:.1f}Â°, mcp_y={ik_input[1]:.3f}, dist={ik_input[2]:.3f}m]")
            
            # æ ¹æ®æ‰‹éƒ¨æ•°æ®è®¡ç®—èˆµæœºä½ç½®
            servo_positions = self._calculate_servo_positions(hand_data)
            
            # ç§»åŠ¨èˆµæœº
            self._move_servos(servo_positions)
        else:
            self._no_hand_count += 1
            if self._no_hand_count == self._no_hand_threshold:
                self._print("æœªæ£€æµ‹åˆ°æ‰‹éƒ¨ï¼Œç­‰å¾…ä¸­...")
            
            # é¢„æµ‹ï¼ˆå¦‚æœæœ‰å¡å°”æ›¼æ»¤æ³¢å™¨ï¼‰
            if self._kalman_filter:
                self._kalman_filter.predict()
                
        return True
        
    def _detect_hand(self, frame) -> Optional[Dict[str, Any]]:
        """
        æ£€æµ‹æ‰‹éƒ¨ï¼Œè¿”å› position, euler, openness
        
        Returns:
            {
                'position': [x, y, z],      # 3Dä½ç½®ï¼ˆç±³ï¼‰
                'euler': [roll, pitch, yaw], # æ¬§æ‹‰è§’ï¼ˆåº¦ï¼‰
                'openness': float,           # å¼ å¼€ç¨‹åº¦ 0-1
                'raw': {...}                 # åŸå§‹æ•°æ®
            }
        """
        if self._hand_detector is None:
            return None
            
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        return self._detect_with_single_hand_detector(rgb, frame.shape)
            
    def _detect_with_single_hand_detector(self, rgb, frame_shape) -> Optional[Dict]:
        """ä½¿ç”¨ EmbeddedSingleHandDetector æ£€æµ‹"""
        num_box, joint_pos, keypoint_2d, wrist_rot, openness, wrist_world_pos, joint_pos_world = \
            self._hand_detector.detect(rgb)
            
        if num_box == 0 or joint_pos is None:
            return None
            
        h, w = frame_shape[:2]
        
        # å‡†å¤‡ 2D å…³é”®ç‚¹
        keypoints_2d = np.array([
            [lm.x * w, lm.y * h] for lm in keypoint_2d.landmark
        ], dtype=np.float32)
        
        # ä¸­æŒ‡æ ¹éƒ¨å…³èŠ‚ï¼ˆMIDDLE_MCP, index=9ï¼‰åœ¨å›¾åƒä¸­çš„ç«–ç›´ä½ç½®ï¼ˆå½’ä¸€åŒ– 0-1ï¼‰
        middle_mcp_y = keypoint_2d.landmark[9].y  # å½’ä¸€åŒ–åæ ‡
        
        # ç”¨äº PnP æ±‚è§£çš„ç‚¹
        X_local = joint_pos[self._keypoint_indices]
        x_2d = keypoints_2d[self._keypoint_indices]
        
        # PnP æ±‚è§£è·å– 3D ä½ç½®
        success, rvec, tvec = self._solve_pnp(X_local, x_2d)
        
        if not success:
            return None
            
        t_raw = tvec.flatten()
        distance = np.linalg.norm(t_raw)
        
        # è·ç¦»å¼‚å¸¸æ£€æµ‹
        t_raw = self._filter_distance(t_raw, distance)
        
        # ä»æ—‹è½¬çŸ©é˜µæå–æ¬§æ‹‰è§’ï¼ˆä¸ä¾èµ– scipyï¼‰
        euler_rad = self._rotation_matrix_to_euler(wrist_rot)
        
        # ç®€å•å¹³æ»‘æ»¤æ³¢
        position = t_raw
        euler_deg = np.degrees(euler_rad)
        openness_filtered = openness if openness is not None else 0.5
        
        if self._smooth_state is not None:
            alpha = self._smooth_alpha
            position = alpha * t_raw + (1 - alpha) * self._smooth_state[:3]
            euler_deg = alpha * euler_deg + (1 - alpha) * self._smooth_state[3:6]
            openness_filtered = alpha * openness_filtered + (1 - alpha) * self._smooth_state[6]
        
        self._smooth_state = np.array([
            position[0], position[1], position[2],
            euler_deg[0], euler_deg[1], euler_deg[2],
            openness_filtered
        ])
        
        # Clip position[2] (è·ç¦») åˆ° 0.25-0.7 ç±³
        position = np.array(position)
        position[2] = np.clip(position[2], 0.25, 0.7)
        
        # Clip euler[1] (pitch) åˆ° Â±30 åº¦
        euler_deg = np.array(euler_deg)
        euler_deg[1] = np.clip(euler_deg[1], -30, 30)
        
        # é€†è§£è¾“å…¥æ•°ç»„: [euler[1](ä¿¯ä»°è§’), middle_mcp_y(ä¸­æŒ‡æ ¹éƒ¨ç«–ç›´ä½ç½®), distance(è·ç¦»)]
        ik_input = [
            float(np.clip((euler_deg[2]-90), -30, 60)),                      # ä¿¯ä»°è§’ (åº¦) åˆ©ç”¨æ‰‹çš„yaw
            float(np.clip(middle_mcp_y, 0.1, 0.8)),   # ä¸­æŒ‡æ ¹éƒ¨ y åæ ‡ (clip åˆ° 0.1-0.8)
            float(position[2])                        # è·ç¦» (ç±³)
        ]
            
        return {
            'position': position.tolist(),
            'euler': euler_deg.tolist(),
            'openness': float(openness_filtered),
            'middle_mcp_y': float(middle_mcp_y),
            'ik_input': ik_input,
            'joint_pos': joint_pos,  # æ·»åŠ å…³èŠ‚ä½ç½®ç”¨äºæ‰‹åŠ¿æ£€æµ‹
            'raw': {
                'tvec': t_raw.tolist(),
                'euler_rad': euler_rad.tolist(),
                'distance': distance,
            }
        }
    
    def _rotation_matrix_to_euler(self, R):
        """ä»æ—‹è½¬çŸ©é˜µæå–æ¬§æ‹‰è§’ (XYZé¡ºåº)"""
        sy = math.sqrt(R[0, 0] ** 2 + R[1, 0] ** 2)
        singular = sy < 1e-6
        
        if not singular:
            x = math.atan2(R[2, 1], R[2, 2])
            y = math.atan2(-R[2, 0], sy)
            z = math.atan2(R[1, 0], R[0, 0])
        else:
            x = math.atan2(-R[1, 2], R[1, 1])
            y = math.atan2(-R[2, 0], sy)
            z = 0
        
        return np.array([x, y, z])
        
    def _solve_pnp(self, object_points, image_points) -> Tuple[bool, Any, Any]:
        """PnP æ±‚è§£"""
        methods = [
            cv2.SOLVEPNP_EPNP,
            cv2.SOLVEPNP_ITERATIVE,
            cv2.SOLVEPNP_SQPNP,
        ]
        
        for method in methods:
            try:
                success, rvec, tvec = cv2.solvePnP(
                    object_points, image_points,
                    self._camera_matrix, self._dist_coeffs,
                    flags=method
                )
                
                if success:
                    # éªŒè¯ç»“æœ
                    distance = np.linalg.norm(tvec)
                    if 0.2 < distance < 1.5:  # åˆç†è·ç¦»èŒƒå›´
                        return True, rvec, tvec
                        
            except cv2.error:
                continue
                
        return False, None, None
        
    def _filter_distance(self, t_raw, distance):
        """è·ç¦»å¼‚å¸¸è¿‡æ»¤"""
        self._distance_history.append(distance)
        if len(self._distance_history) > self._max_history:
            self._distance_history.pop(0)
            
        if len(self._distance_history) > 5:
            avg = np.mean(self._distance_history)
            std = np.std(self._distance_history)
            z_score = abs(distance - avg) / (std + 1e-6)
            
            if z_score > 2.0:
                t_raw = t_raw.copy()
                t_raw[2] = avg
                
        return t_raw
        
    def _calculate_servo_positions(self, hand_data: Dict) -> Dict[int, int]:
        """
        æ ¹æ®æ‰‹éƒ¨æ•°æ®è®¡ç®—èˆµæœºä½ç½®ï¼ˆä½¿ç”¨é€†è§£ç®—ï¼‰
        
        æ˜ å°„å…³ç³»:
        - ik_input[0] = pitch = beta (ç¯ä¿¯ä»°)
        - ik_input[1] = middle_mcp_y: 0.8~0.1 â†’ y: 0.1~0.28
        - ik_input[2] = distance: 0.7~0.25 â†’ x: -0.22~0
        - theta_0 = atan2(y, x)
        - b = sqrt(xÂ² + yÂ²), çº¦æŸåˆ° <= 0.28
        """
        ik_input = hand_data.get('ik_input')
        if ik_input is None:
            return self.current_positions
        
        beta_deg = ik_input[0]    # pitch â†’ beta
        mcp_y = ik_input[1]       # 0.1~0.8
        dist = ik_input[2]        # 0.25~0.7
        
        # === æ˜ å°„åˆ° x, y ===
        # x: dist 0.7â†’-0.22, dist 0.25â†’0
        x = -0.22 * (dist - 0.25) / (0.7 - 0.25)
        
        # y: mcp_y 0.8â†’0.1, mcp_y 0.1â†’0.28
        y = 0.1 + (0.28 - 0.1) * (0.8 - mcp_y) / (0.8 - 0.1)
        
        # === ä» x, y è®¡ç®— b å’Œ theta_0 ===
        b = math.sqrt(x**2 + y**2)
        
        # æ£€æŸ¥æ˜¯å¦åœ¨åœ†å¤–ï¼Œå¦‚æœ b > 0.28 åˆ™çº¦æŸåˆ° 0.28
        if b > 0.28:
            b = 0.28
        
        # theta_0 = atan2(y, x)ï¼Œè½¬æ¢ä¸ºåº¦
        if abs(x) < 1e-6:
            theta_0_deg = 90.0 if y > 0 else -90.0
        else:
            theta_0_deg = math.degrees(math.atan2(y, x))
        
        # === é€†è§£ç®— ===
        alpha_1, alpha_2, alpha_3, valid = self._inverse_kinematics(b, theta_0_deg, beta_deg)
        
        if not valid:
            self._debug(f"IK æ— æ•ˆ: b={b:.3f}, theta_0={theta_0_deg:.1f}, beta={beta_deg:.1f}")
            return self.current_positions
        
        # === è§’åº¦è½¬ç¼–ç  ===
        enc_3 = self._angle_to_encoder(3, alpha_1)  # åº•éƒ¨
        enc_2 = self._angle_to_encoder(2, alpha_2)  # ä¸­é—´
        enc_1 = self._angle_to_encoder(1, alpha_3)  # é¡¶ç«¯
        
        self._debug(f"IK: x={x:.3f}, y={y:.3f} â†’ b={b:.3f}, Î¸â‚€={theta_0_deg:.1f}Â°, Î²={beta_deg:.1f}Â°")
        self._debug(f"    Î±â‚={alpha_1:.1f}Â°, Î±â‚‚={alpha_2:.1f}Â°, Î±â‚ƒ={alpha_3:.1f}Â° â†’ enc=[{enc_3}, {enc_2}, {enc_1}]")
        
        return {
            3: enc_3,  # åº•éƒ¨
            2: enc_2,  # ä¸­é—´
            1: enc_1,  # é¡¶ç«¯
        }
    
    def _inverse_kinematics(self, b, theta_0_deg, beta_deg=0):
        """
        å°ç¯è¿æ†é€†è§£ç®—ï¼ˆè°ƒç”¨å…±äº«æ¨¡å—ï¼‰
        
        Args:
            b: ç­‰è…°ä¸‰è§’å½¢åº•è¾¹é•¿ (ç±³)
            theta_0_deg: åº•è¾¹è§’åº¦ (åº¦)
            beta_deg: ç¯ä¿¯ä»°è§’åº¦ (åº¦)
        
        Returns:
            (alpha_1, alpha_2, alpha_3, valid): ä¸‰ä¸ªèˆµæœºè§’åº¦, æ˜¯å¦æœ‰æ•ˆ
        """
        return inverse_kinematics(b, theta_0_deg, beta_deg)
    
    def _angle_to_encoder(self, servo_id, angle_deg):
        """è§’åº¦è½¬æ¢ä¸ºç¼–ç å€¼ï¼ˆè°ƒç”¨å…±äº«æ¨¡å—ï¼‰"""
        return angle_to_encoder(servo_id, angle_deg)
        
    def _move_servos(self, positions: Dict[int, int], speed: int = None):
        """ç§»åŠ¨èˆµæœºï¼ˆå¸¦é¢‘ç‡æ§åˆ¶ï¼‰"""
        import time
        now = time.time()
        
        # é¢‘ç‡æ§åˆ¶ï¼šæ—¶é—´æ²¡åˆ°å°±è·³è¿‡
        if now - self._last_servo_send_time < self._servo_send_interval:
            return
        self._last_servo_send_time = now
        
        if self.controller:
            servo_thread = getattr(self.controller, '_servo_thread', None)
            self._print(f"[DEBUG] _move_servos: controller={self.controller is not None}, servo_thread={servo_thread is not None}")
            if servo_thread:
                self._print(f"[DEBUG] å‡†å¤‡å‘é€èˆµæœºå‘½ä»¤: {positions}")
                for servo_id, pos in positions.items():
                    # é™å¹…
                    min_pos, max_pos = self.servo_limits.get(servo_id, (0, 1023))
                    pos = max(min_pos, min(max_pos, pos))
                    servo_thread.move(servo_id, pos, speed if speed else 500)
                    self.current_positions[servo_id] = pos
            else:
                # æ¨¡æ‹Ÿæ¨¡å¼
                self._print(f"[DEBUG] servo_thread ä¸º None! ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
                self._debug(f"[MockServo] ç§»åŠ¨: {positions}")
        else:
            self._print(f"[DEBUG] controller ä¸º None!")
                
    def handle_voice(self, text: str) -> bool:
        """å¤„ç†è¯­éŸ³å‘½ä»¤"""
        return False
        
    def get_hand_data(self) -> Optional[Dict[str, Any]]:
        """è·å–æœ€æ–°çš„æ‰‹éƒ¨æ•°æ®ï¼ˆä¾›å¤–éƒ¨ä½¿ç”¨ï¼‰"""
        return self._hand_data


# ==================== ç‹¬ç«‹æµ‹è¯• ====================

# èˆµæœºæ§åˆ¶é…ç½®
SERIAL_PORT = '/dev/ttyUSB0'
BAUDRATE = 1000000


class RealServoController:
    """çœŸæ­£çš„èˆµæœºæ§åˆ¶å™¨ï¼ˆç”¨äºç‹¬ç«‹æµ‹è¯•ï¼‰"""
    
    # å¯„å­˜å™¨åœ°å€
    STS_GOAL_POSITION_L = 42
    
    def __init__(self, port=SERIAL_PORT, baudrate=BAUDRATE):
        self.port = port
        self.baudrate = baudrate
        self.port_handler = None
        self.packet_handler = None
        self._connected = False
        self._speed = 500  # é»˜è®¤é€Ÿåº¦
        
    def connect(self) -> bool:
        """è¿æ¥èˆµæœº"""
        try:
            import sys
            import os
            # æ·»åŠ  scservo_sdk è·¯å¾„
            sdk_path = os.path.join(os.path.dirname(__file__), '..', '..', '..', '..', 'FTServo_Python')
            sys.path.insert(0, os.path.abspath(sdk_path))
            
            from scservo_sdk import PortHandler, sms_sts, COMM_SUCCESS
            
            self.COMM_SUCCESS = COMM_SUCCESS
            
            # æ‰“å¼€ä¸²å£
            self.port_handler = PortHandler(self.port)
            if not self.port_handler.openPort():
                print(f"âœ— æ— æ³•æ‰“å¼€ä¸²å£: {self.port}")
                return False
            
            if not self.port_handler.setBaudRate(self.baudrate):
                print(f"âœ— æ— æ³•è®¾ç½®æ³¢ç‰¹ç‡: {self.baudrate}")
                return False
            
            # ä½¿ç”¨ sms_sts åè®®å¤„ç†å™¨
            self.packet_handler = sms_sts(self.port_handler)
            
            self._connected = True
            print(f"âœ“ èˆµæœºè¿æ¥æˆåŠŸ: {self.port} @ {self.baudrate}")
            return True
            
        except ImportError as e:
            print(f"âœ— scservo_sdk å¯¼å…¥å¤±è´¥: {e}")
            return False
        except Exception as e:
            print(f"âœ— è¿æ¥å¤±è´¥: {e}")
            return False
    
    def disconnect(self):
        """æ–­å¼€è¿æ¥"""
        if self.port_handler:
            self.port_handler.closePort()
            self._connected = False
            print("èˆµæœºæ–­å¼€è¿æ¥")
    
    def write_position(self, servo_id: int, position: int, speed: int = None):
        """å†™å…¥å•ä¸ªèˆµæœºä½ç½®å’Œé€Ÿåº¦ï¼ˆå¤§ç«¯åºï¼Œå’Œ my_servo_control.py ä¸€è‡´ï¼‰"""
        if not self._connected:
            return
        
        position = max(0, min(1023, position))
        speed = speed if speed is not None else self._speed
        
        # æ•°æ®åŒ…: ä½ç½®é«˜, ä½ç½®ä½, æ—¶é—´é«˜, æ—¶é—´ä½, é€Ÿåº¦é«˜, é€Ÿåº¦ä½
        data = [
            (position >> 8) & 0xFF,  # ä½ç½®é«˜å­—èŠ‚
            position & 0xFF,         # ä½ç½®ä½å­—èŠ‚
            0, 0,                    # æ—¶é—´ï¼ˆä¸ä½¿ç”¨ï¼‰
            (speed >> 8) & 0xFF,     # é€Ÿåº¦é«˜å­—èŠ‚
            speed & 0xFF             # é€Ÿåº¦ä½å­—èŠ‚
        ]
        
        try:
            self.packet_handler.writeTxRx(servo_id, self.STS_GOAL_POSITION_L, len(data), data)
        except Exception as e:
            print(f"å†™å…¥èˆµæœº {servo_id} å¤±è´¥: {e}")
    
    def sync_move(self, positions: Dict[int, int], speed: int = None):
        """é€ä¸ªå†™å…¥èˆµæœºä½ç½®ï¼ˆéåŒæ­¥å¹¿æ’­ï¼Œé€ä¸ªå‘é€ï¼‰"""
        if not self._connected:
            return
        
        for servo_id, pos in positions.items():
            self.write_position(servo_id, pos, speed)


class _TestServoThread:
    """
    ç‹¬ç«‹æµ‹è¯•ç”¨çš„èˆµæœºå‘é€çº¿ç¨‹ï¼ˆé¿å…ä¸ modules/servo/servo_thread.py æ··æ·†ï¼‰
    
    ä¸»çº¿ç¨‹è°ƒç”¨ set_position() åªæ˜¯æŠŠæŒ‡ä»¤å¡è¿›é˜Ÿåˆ—ï¼Œç«‹å³è¿”å›ã€‚
    ç‹¬ç«‹çº¿ç¨‹å¾ªç¯ä»é˜Ÿåˆ—å–æŒ‡ä»¤ï¼Œè°ƒç”¨ writeTxRx å‘é€ã€‚
    """
    
    def __init__(self, servo_controller: RealServoController):
        import threading
        import queue
        
        self._controller = servo_controller
        self._speed = 500  # é»˜è®¤é€Ÿåº¦
        
        # æŒ‡ä»¤é˜Ÿåˆ—ï¼ˆæœ€å¤šç¼“å­˜10ä¸ªï¼Œæ»¡äº†å°±ä¸¢å¼ƒæ—§çš„ï¼‰
        self._queue = queue.Queue(maxsize=10)
        
        # å‘é€çº¿ç¨‹
        self._running = True
        self._thread = threading.Thread(target=self._send_loop, daemon=True, name="ServoSendThread")
        self._thread.start()
        print("âœ“ èˆµæœºå‘é€çº¿ç¨‹å·²å¯åŠ¨")
    
    def set_position(self, servo_id: int, position: int, speed: int = None):
        """
        è®¾ç½®èˆµæœºä½ç½®ï¼ˆéé˜»å¡ï¼Œå¡è¿›é˜Ÿåˆ—ç«‹å³è¿”å›ï¼‰
        """
        import queue
        spd = speed if speed is not None else self._speed
        try:
            # put_nowait: é˜Ÿåˆ—æ»¡å°±æŠ›å¼‚å¸¸ï¼Œä¸é˜»å¡
            self._queue.put_nowait((servo_id, position, spd))
        except queue.Full:
            # é˜Ÿåˆ—æ»¡äº†ï¼Œä¸¢å¼ƒè¿™æ¡æŒ‡ä»¤ï¼ˆä¿è¯å®æ—¶æ€§ï¼‰
            pass
    
    def _send_loop(self):
        """å‘é€çº¿ç¨‹ä¸»å¾ªç¯ï¼šä¸æ–­ä»é˜Ÿåˆ—å–æŒ‡ä»¤å‘é€"""
        while self._running:
            try:
                # ç­‰å¾…æŒ‡ä»¤ï¼Œè¶…æ—¶0.1ç§’æ£€æŸ¥ä¸€æ¬¡ _running
                servo_id, position, speed = self._queue.get(timeout=0.1)
                self._controller.write_position(servo_id, position, speed)
            except:
                # queue.Empty æˆ–å…¶ä»–å¼‚å¸¸ï¼Œç»§ç»­å¾ªç¯
                pass
    
    def stop(self):
        """åœæ­¢å‘é€çº¿ç¨‹"""
        self._running = False
        if self._thread.is_alive():
            self._thread.join(timeout=1)
        print("èˆµæœºå‘é€çº¿ç¨‹å·²åœæ­¢")


def test_hand_follow_mode():
    """ç‹¬ç«‹æµ‹è¯•æ‰‹éƒ¨è·Ÿéšæ¨¡å¼ï¼ˆçœŸå®èˆµæœºæ§åˆ¶ï¼‰"""
    print("=" * 50)
    print("æ‰‹éƒ¨è·Ÿéšæ¨¡å¼ - ç‹¬ç«‹æµ‹è¯• (çœŸå®èˆµæœº)")
    print("=" * 50)
    print("è¯»å–æ•°æ®: position, euler, openness")
    print(f"ä¸²å£: {SERIAL_PORT}")
    print("æŒ‰ 'q' é€€å‡ºæµ‹è¯•")
    print()
    
    # åˆ›å»ºçœŸå®èˆµæœºæ§åˆ¶å™¨
    servo_controller = RealServoController(SERIAL_PORT, BAUDRATE)
    
    class TestController:
        def __init__(self):
            self.debug = True
            self._servo_thread = None
    
    controller = TestController()
    
    # å°è¯•è¿æ¥èˆµæœº
    if servo_controller.connect():
        controller._servo_thread = _TestServoThread(servo_controller)
        print("âœ“ ä½¿ç”¨çœŸå®èˆµæœºæ§åˆ¶")
    else:
        print("âš  èˆµæœºè¿æ¥å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
    
    mode = HandFollowMode(controller)
    
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("é”™è¯¯: æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
        return
        
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    
    mode.enter()
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
                
            mode.update(frame=frame)
            
            # æ˜¾ç¤ºæ‰‹éƒ¨æ•°æ®
            hand_data = mode.get_hand_data()
            if hand_data:
                pos = hand_data['position']
                euler = hand_data['euler']
                openness = hand_data['openness']
                ik_input = hand_data['ik_input']
                
                y = 30
                cv2.putText(frame, f"Pos: [{pos[0]:.2f}, {pos[1]:.2f}, {pos[2]:.2f}]",
                           (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                y += 30
                cv2.putText(frame, f"Euler: [{euler[0]:.1f}, {euler[1]:.1f}, {euler[2]:.1f}]",
                           (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                y += 30
                cv2.putText(frame, f"Openness: {openness:.2f}",
                           (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                y += 30
                # é€†è§£è¾“å…¥æ•°ç»„: [pitch, middle_mcp_y, distance]
                cv2.putText(frame, f"IK Input: [{ik_input[0]:.1f}, {ik_input[1]:.3f}, {ik_input[2]:.3f}]",
                           (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
            else:
                cv2.putText(frame, "No hand detected", (10, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                           
            cv2.putText(frame, "Press 'q' to quit", (10, frame.shape[0] - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                       
            cv2.imshow("Hand Follow Mode Test", frame)
            
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
                
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­")
    finally:
        mode.exit()
        cap.release()
        cv2.destroyAllWindows()
        
        # åœæ­¢èˆµæœºå‘é€çº¿ç¨‹
        if controller._servo_thread:
            controller._servo_thread.stop()
        
        # æ–­å¼€èˆµæœºè¿æ¥
        if servo_controller._connected:
            servo_controller.disconnect()
        
        print("æµ‹è¯•ç»“æŸ")


if __name__ == "__main__":
    test_hand_follow_mode()
